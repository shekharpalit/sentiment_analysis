{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimental",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shekharpalit/sentiment_analysis/blob/master/sentimental.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9J7p406abzgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. See our [FAQ](https://research.google.com/colaboratory/faq.html) for more info."
      ]
    },
    {
      "metadata": {
        "id": "fkLq-VqB03Bn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "14e37190-1085-4c13-93f5-5eca3809e9d3"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59330000 @  0x7f34362fc1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3BUH-q5H15p9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0k0TUvu2CxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#bulding a sentiment classifier \n",
        "\n",
        "#downloading IMDb data and performing text tokenization\n",
        "#building vocab\n",
        "#generating batches of vectors\n",
        "#creating a network model with embeddings\n",
        "#training model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyswMwY12Urt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5fe8ab22-0aef-409c-ec7a-e3654ee8c982"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c6cc000 @  0x7f17a0c831c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "0.4.1\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ckUby692mPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "0879704e-a92d-49e2-cb66-de49eb85d58a"
      },
      "cell_type": "code",
      "source": [
        "!pip install torchtext\n",
        "!pip install spaCy\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.8.24)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.2.3\n",
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.6/dist-packages (2.0.12)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.14.5)\n",
            "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.28.0)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.31.2)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.0.1)\n",
            "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.6/dist-packages (from spaCy) (6.10.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.9.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.35)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.2.8.2)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spaCy) (2017.4.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (2.18.4)\n",
            "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (0.5.6)\n",
            "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (0.4.3.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (0.9.0.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (1.10.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (4.26.0)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spaCy) (1.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2018.8.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.6)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spaCy) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bjtko4lxG4vL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "27f3dc71-dce4-4677-9a77-95102e5b8a9c"
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en  \n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 1.1MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u3E-jZX-2rZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "LABEL = data.LabelField(tensor_type= torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LJ9FzaMGHL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7efb29ac-7d17-4d35-83f6-ce0df286dd22"
      },
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6TNHoFZHZ6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "556d0a23-c786-4748-bde4-98f3188394fc"
      },
      "cell_type": "code",
      "source": [
        "print('length of train:',len(train))\n",
        "print('length of test:', len(test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train: 25000\n",
            "length of test: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x0nUT88sImE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5abd946b-c8ea-4363-8dff-6fac68db24d6"
      },
      "cell_type": "code",
      "source": [
        "print('fields of text :', train.fields)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fields of text : {'text': <torchtext.data.field.Field object at 0x7f16077ede80>, 'label': <torchtext.data.field.LabelField object at 0x7f16077edeb8>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G3pzKVfHI9-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a294cf5e-b3a7-4ba4-8f59-b8162d0dd2aa"
      },
      "cell_type": "code",
      "source": [
        "print('frequency of train:', train.freqs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency of train: <generator object Dataset.__getattr__ at 0x7f160cda6fc0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i1nBar-3JKQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9935b939-0ea9-4c8d-9657-4725d0d8fbb4"
      },
      "cell_type": "code",
      "source": [
        "print('vars(train[0])', vars(train[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vars(train[0]) {'text': ['Hare', 'Rama', 'Hare', 'Krishna', 'was', 'the', 'biggest', 'hit', 'movie', 'of', '1971', '.', 'Filmed', 'almost', 'entirely', 'in', 'Kathmandu', ',', 'the', 'capital', 'of', 'Nepal', ',', 'the', 'movie', 'depicts', 'not', 'only', 'with', 'the', 'theme', 'of', 'a', 'broken', 'family', ',', 'but', 'also', 'a', 'relationship', 'between', 'a', 'brother', 'and', 'a', 'sister', ',', 'as', 'well', 'as', 'drugs', 'and', 'the', 'hippie', 'movement', ',', 'which', 'made', 'many', 'people', 'think', 'that', 'it', 'involved', 'the', 'ISKON', '-', 'the', 'movement', 'for', 'Krishna', 'consciousness.<br', '/><br', '/>The', 'movie', 'begins', 'with', 'scenes', 'of', 'drugs', 'and', 'being', 'informed', 'that', 'the', 'woman', 'dancing', 'in', 'front', 'is', 'the', 'narrator', \"'s\", 'sister', '.', 'Going', 'back', 'to', 'the', 'past', 'the', 'brother', 'and', 'sister', 'are', 'happily', 'playing', 'around', 'the', 'house', 'only', 'to', 'hear', 'their', 'parents', 'arguing', '.', 'This', 'soon', 'leads', 'to', 'a', 'split', 'in', 'the', 'family', '.', 'The', 'brother', 'goes', 'with', 'the', 'mother', 'and', 'the', 'sister', 'with', 'the', 'father.<br', '/><br', '/>As', 'years', 'pass', ',', 'the', 'brother', 'goes', 'in', 'search', 'of', 'his', 'sister', 'and', 'is', 'informed', 'that', 'she', 'no', 'longer', 'lives', 'with', 'the', 'father', 'and', 'that', 'she', 'has', 'moved', 'to', 'Nepal', '.', 'Here', ',', 'Prashant', ',', 'the', 'brother', 'not', 'only', 'finds', 'love', ',', 'but', 'he', 'also', 'finds', 'his', 'sister', ',', 'Janice', '.', 'But', 'he', 'finds', 'out', 'that', 'she', 'is', 'not', 'only', 'in', 'the', 'wrong', 'company', 'of', 'friends', 'but', 'is', 'also', 'on', 'drugs', 'as', 'she', 'wants', 'to', 'block', 'all', 'memory', 'of', 'her', 'past', '.', 'With', 'help', 'of', 'Shanti', ',', 'his', 'love', ',', 'the', 'brother', 'tries', 'to', 'get', 'his', 'sister', 'away', 'from', 'all', 'this', 'but', 'has', 'to', 'overcome', 'many', 'obstacles', ',', 'including', 'people', 'who', 'stoop', 'to', 'all', 'sorts', 'of', 'levels', 'to', 'stop', 'him', 'This', 'is', 'a', 'multi', 'cast', 'movie', 'and', 'is', 'led', 'by', 'the', 'director', 'and', 'producer', 'himself', ',', 'Dev', 'Anand', 'and', 'also', 'stars', 'Zeenat', 'Aman', '(', 'her', 'first', 'movie', ')', ',', 'Mumtaz', ',', 'Rajendranath', ',', 'Prem', 'Chopra', ',', 'Jnr', 'Mehmood', ',', 'A.K.', 'Hangal', 'and', 'Achala', 'Sachdev', '.', 'The', 'music', 'is', 'superbly', 'provided', 'by', 'the', 'late', 'R.D.', 'Burman', ',', 'whose', 'last', 'score', 'was', '\"', '1942', '-', 'A', 'Love', 'Story', '.', '\"', 'During', 'the', 'filming', ',', 'Dev', 'Anand', 'asked', 'Panchamda', '(', 'R.D.', 'Burman', ')', 'to', 'compose', 'something', 'special', 'for', 'this', 'film', '.', 'Days', 'later', 'Panchamda', 'came', 'back', 'with', 'the', 'composition', 'of', '\"', 'Dum', 'Maro', 'Dum', '.', '\"', 'The', 'song', 'was', 'an', 'instant', 'hit', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-UgvLPDKJqHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train, valid = train.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1AU_a27KF2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c68cc77c-74f5-4620-81c0-e2e65a7c5e08"
      },
      "cell_type": "code",
      "source": [
        "print('len(train):',len(train))\n",
        "print('len(valid):', len(valid))\n",
        "print('len(test):', len(test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(train): 17500\n",
            "len(valid): 7500\n",
            "len(test): 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W4ZWzOQCKKw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9dd0bda1-d9a7-43ab-f018-270f5b88bd72"
      },
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train, max_size = 25000, vectors = \"glove.6B.100d\")\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [00:46, 18.6MB/s]                           \n",
            "100%|██████████| 400000/400000 [00:20<00:00, 19501.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pOUsxeOfGoau",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8FUbHsCB3BEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01749f0b-4cac-4c2c-aa69-b673419e0ebb"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHpi5iwHK3cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "df7acf9b-1f23-4acd-e0b8-d1fb2bb82308"
      },
      "cell_type": "code",
      "source": [
        "print('len(TEXT.vocab):', len(TEXT.vocab))\n",
        "print('len(LABEL.vocab):', len(LABEL.vocab))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(TEXT.vocab): 25002\n",
            "len(LABEL.vocab): 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oDcxaWSYLCwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "30f24eb6-0b86-418a-a8f7-80a60b252269"
      },
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 203175), (',', 193461), ('.', 165729), ('and', 109689), ('a', 109322), ('of', 101341), ('to', 93866), ('is', 76374), ('in', 61316), ('I', 54344), ('it', 53272), ('that', 49248), ('\"', 44813), (\"'s\", 43487), ('this', 42402), ('-', 37022), ('/><br', 35978), ('was', 35147), ('as', 30416), ('with', 30030)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9suawJHLXrD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_itr, valid_itr, test_itr = data.BucketIterator.splits((train,test,valid), batch_size = BATCH_SIZE, sort_key = lambda x:len(x.text), repeat = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6_GKWUSNOLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout)\n",
        "    self.fc = nn.Linear(hidden_dim *2, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    embedded = self.dropout(self.embedding(x))\n",
        "    \n",
        "    output, (hidden, cell) = self.rnn(embedded)\n",
        "    \n",
        "    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "\n",
        "    return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmwKMguLRa9Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHZS4vEEIBj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1793407e-dbe6-4a1c-e0b6-0b4d86f37551"
      },
      "cell_type": "code",
      "source": [
        "pretrained_embedding = TEXT.vocab.vectors\n",
        "print(pretrained_embedding.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DoVJaiOqIByP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "0692a198-389b-477e-aabf-c65709dc8cba"
      },
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embedding)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "RkD80FtVSln8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TRAIN THE MODEL\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eK8j62WFTXv3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "go71xsyOlU7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32bd0337-1463-452b-a89e-ad3ba6302c27"
      },
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T45u7lReUEnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tJxD1YtTUkkg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def binary_accuracy(preds, y):\n",
        "  rounds_preds = torch.round(F.sigmoid(preds))\n",
        "  correct = (rounds_preds == y).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVecurevVwr2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss/len(iterator), epoch_acc/len(iterator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0d5WrgzW6xi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "       for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RkcaWKkaYN80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "30e6c169-289c-412f-9fb3-d1993c24834a"
      },
      "cell_type": "code",
      "source": [
        "N_EPOCH = 5\n",
        "for epoch in range(N_EPOCH):\n",
        "  train_loss, train_acc = train(model, train_itr, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_itr, criterion)\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  r\"\"\"A simple lookup table that looks up embeddings in a fixed dictionary and size.\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01, Train Loss: 0.681, Train Acc: 55.61%, Val. Loss: 0.642, Val. Acc: 64.49%\n",
            "Epoch: 02, Train Loss: 0.602, Train Acc: 68.53%, Val. Loss: 0.586, Val. Acc: 69.02%\n",
            "Epoch: 03, Train Loss: 0.480, Train Acc: 77.80%, Val. Loss: 0.478, Val. Acc: 78.32%\n",
            "Epoch: 04, Train Loss: 0.515, Train Acc: 73.00%, Val. Loss: 0.445, Val. Acc: 82.05%\n",
            "Epoch: 05, Train Loss: 0.298, Train Acc: 87.85%, Val. Loss: 0.354, Val. Acc: 85.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S6b2qineYr_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d2116e2a-f4db-4d6e-fb40-f845f85c9dd1"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_itr, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return Variable(arr, volatile=not train)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  r\"\"\"A simple lookup table that looks up embeddings in a fixed dictionary and size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.299, Test Acc: 87.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hMVJVTE2eAJD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}